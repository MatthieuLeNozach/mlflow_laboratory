{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **MLFLow-laboratory**\n",
    "> \n",
    "> \n",
    "> #### **a. Choose a model**\n",
    "> All scikit-learn models are available with one single import at `project_root/lib/models/sklearn.py`\n",
    "> ```py\n",
    "> # Import a model with:\n",
    "> from lib.models.sklearn import RandomForestClassifier\n",
    "> rfc = RandomForestClassifier()*\n",
    ">\n",
    "> # Or import all classes in a dict at once with:\n",
    "> from lib.models.sklearn import SKLEARN_CLASSIFIERS\n",
    "> # ... and instantiate them with:\n",
    "> rfc = SKLEARN_CLASSIFIERS['RandomForestClassisier'](bootstrap=True)\n",
    "> svc = SKLEARN_CLASSIFIERS['SVC']()\n",
    "> ```\n",
    "> #### **b. Select hyperparameters**\n",
    "> Automatic hyperparameter tuning is performed with Optuna library,\n",
    "> More information is available at [https://optuna.readthedocs.io/](https://optuna.readthedocs.io/en/stable/tutorial/index.html).  \n",
    "> \n",
    "> **WIP** An hyperparameter bank is being built, see at `project_root/lib/hp/...`\n",
    "> The goal is to store their name, a range if they are numerical or a list of choices.  \n",
    "> Here's an example:\n",
    "> ```py\n",
    "> # Hyperparameters for RandomForestClassifier\n",
    "> RFC_SPACE = {\n",
    ">     'classifier__n_estimators': (20, 200),\n",
    ">     'classifier__max_depth': (10, 100),\n",
    ">     'classifier__min_samples_split': (2, 20),\n",
    ">     'classifier__min_samples_leaf': (1, 2),\n",
    ">     'classifier__max_features': ['sqrt', 'log2', None],\n",
    ">     'classifier__criterion': ['gini', 'entropy'],\n",
    "> }\n",
    "> ```\n",
    "> Hyperparameter naming convention is `XXXC_SPACE` (ex `KNNC_SPACE`) for classification, / XXXR_SPACE (ex `RFR_SPACE`) for regression.  \n",
    "> \n",
    ">  Load hyperparameters:\n",
    "> ```bash\n",
    "> # Enable custom magics\n",
    "> %load_ext custom_magics\n",
    "> # load a set of hyperparameters\n",
    "> %load_variables ../lib/hp/sklearn.py RFC_SPACE\n",
    "> ```\n",
    "> #### **a. Retrieve scripts**\n",
    "> \n",
    "> Paste and execute one of these commands into a code cell to retrieve a mlflow script:\n",
    "> \n",
    "> **Classification**  \n",
    "> - Binary: `%load ../scripts/binary_classification.py`\n",
    "> \n",
    "> **Regression**  \n",
    "> - #TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Base config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE MODEL\n",
    "from lib.models.sklearn import SKLEARN_CLSSIFIERS\n",
    "rfc = SKLEARN_CLSSIFIERS['RandomForestClassifier'](bootstrap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The custom_magics module is not an IPython extension.\n"
     ]
    }
   ],
   "source": [
    "%load_ext custom_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_variables lib/hp/sklearn.py RFC_SPACE\n",
    "RFC_SPACE = {   'classifier__criterion': ['gini', 'entropy'],\n",
    "    'classifier__max_depth': (10, 100),\n",
    "    'classifier__max_features': ['sqrt', 'log2', None],\n",
    "    'classifier__min_samples_leaf': (1, 2),\n",
    "    'classifier__min_samples_split': (2, 20),\n",
    "    'classifier__n_estimators': (20, 200)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load the script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mln/git_explore/perso/mlflow_laboratory/notebooks\n",
      "['custom_magics.py', '__pycache__', 'template copy 2.ipynb', 'template copy 3.ipynb']\n",
      "MINIO_ENDPOINT_URL: set\n",
      "MINIO_ACCESS_KEY: set\n",
      "MINIO_SECRET_KEY: set\n",
      "MLFLOW_TRACKING_URI: http://localhost:5000\n",
      "mlflow tracking URI has been set to  http://localhost:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-26 13:34:20,250] A new study created in memory with name: no-name-b07b28b7-bce8-4d87-9c2a-55ac50ac6abc\n",
      "[I 2024-03-26 13:34:20,401] Trial 0 finished with value: 0.8955223880597015 and parameters: {'classifier__n_estimators': 40, 'classifier__max_depth': 67, 'classifier__min_samples_split': 19, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'log2', 'classifier__criterion': 'entropy'}. Best is trial 0 with value: 0.8955223880597015.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: optuna_experiment14, ID: 3\n",
      "Initial trial 0 achieved value: 0.8955223880597015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-26 13:34:20,752] Trial 1 finished with value: 0.9064039408866995 and parameters: {'classifier__n_estimators': 21, 'classifier__max_depth': 10, 'classifier__min_samples_split': 19, 'classifier__min_samples_leaf': 1, 'classifier__max_features': None, 'classifier__criterion': 'gini'}. Best is trial 1 with value: 0.9064039408866995.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 achieved value: 0.9064039408866995 with  1.2005% improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-26 13:34:22,523] Trial 2 finished with value: 0.916256157635468 and parameters: {'classifier__n_estimators': 107, 'classifier__max_depth': 43, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1, 'classifier__max_features': None, 'classifier__criterion': 'gini'}. Best is trial 2 with value: 0.916256157635468.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 achieved value: 0.916256157635468 with  1.0753% improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-26 13:34:22,794] Trial 3 finished with value: 0.9 and parameters: {'classifier__n_estimators': 84, 'classifier__max_depth': 38, 'classifier__min_samples_split': 13, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'log2', 'classifier__criterion': 'gini'}. Best is trial 2 with value: 0.916256157635468.\n",
      "[I 2024-03-26 13:34:25,248] Trial 4 finished with value: 0.9108910891089109 and parameters: {'classifier__n_estimators': 159, 'classifier__max_depth': 82, 'classifier__min_samples_split': 8, 'classifier__min_samples_leaf': 2, 'classifier__max_features': None, 'classifier__criterion': 'gini'}. Best is trial 2 with value: 0.916256157635468.\n",
      "[I 2024-03-26 13:34:25,644] Trial 5 finished with value: 0.9 and parameters: {'classifier__n_estimators': 121, 'classifier__max_depth': 68, 'classifier__min_samples_split': 18, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'sqrt', 'classifier__criterion': 'entropy'}. Best is trial 2 with value: 0.916256157635468.\n",
      "[I 2024-03-26 13:34:25,856] Trial 6 finished with value: 0.9 and parameters: {'classifier__n_estimators': 68, 'classifier__max_depth': 37, 'classifier__min_samples_split': 20, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'log2', 'classifier__criterion': 'entropy'}. Best is trial 2 with value: 0.916256157635468.\n",
      "[I 2024-03-26 13:34:26,334] Trial 7 finished with value: 0.9054726368159204 and parameters: {'classifier__n_estimators': 132, 'classifier__max_depth': 87, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'sqrt', 'classifier__criterion': 'gini'}. Best is trial 2 with value: 0.916256157635468.\n",
      "[I 2024-03-26 13:34:26,683] Trial 8 finished with value: 0.9054726368159204 and parameters: {'classifier__n_estimators': 92, 'classifier__max_depth': 31, 'classifier__min_samples_split': 9, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'sqrt', 'classifier__criterion': 'gini'}. Best is trial 2 with value: 0.916256157635468.\n",
      "[I 2024-03-26 13:34:28,900] Trial 9 finished with value: 0.9054726368159204 and parameters: {'classifier__n_estimators': 183, 'classifier__max_depth': 34, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 2, 'classifier__max_features': None, 'classifier__criterion': 'entropy'}. Best is trial 2 with value: 0.916256157635468.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS FROM main():  {'classifier__n_estimators': 107, 'classifier__max_depth': 43, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1, 'classifier__max_features': None, 'classifier__criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "# %load ../scripts/binary_classification.py\n",
    "# file: binary_classification.py\n",
    "\n",
    "# FIND REGULAR IMPORTS IN laboratory/config.py\n",
    "from laboratory.config import *\n",
    "from laboratory.mlflow import get_or_create_experiment, set_mlflow_tracking_uri_from_env\n",
    "\n",
    "handle_warnings()\n",
    "env_vars = get_environment()\n",
    "set_mlflow_tracking_uri_from_env(env_vars)\n",
    "\n",
    "# Custom modules\n",
    "import laboratory.dataset as dataset\n",
    "import laboratory.pipeline as pipeline\n",
    "import laboratory.tuning as tuning\n",
    "from laboratory.artifacts import log_confusion_matrix, log_roc_curve\n",
    "from lib.hp.sklearn import RFC_SPACE\n",
    "from lib.models.sklearn import RandomForestClassifier\n",
    "\n",
    "\n",
    "#################### SETUP ####################\n",
    "EXPERIMENT_NAME = 'optuna_experiment14'\n",
    "RUN_NAME = 'hyperparameter_optimization'\n",
    "DATASET_PATH = '../../../0_DATASETS/creditcard.csv'\n",
    "CLASSIFIER = RandomForestClassifier(bootstrap=False)\n",
    "SPACE = RFC_SPACE \n",
    "TARGET_NAME = 'Class'\n",
    "SAVE_MODEL = False\n",
    "\n",
    "#################### MAIN ####################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = pd.read_csv(DATASET_PATH)\n",
    "    df_redux = dataset.data_split_redux(df, TARGET_NAME, zero_label_redux=0.995)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = dataset.train_test_split(\n",
    "        df_redux.drop(columns=TARGET_NAME), df_redux[TARGET_NAME], test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    num_features = X_train.select_dtypes([np.number]).columns.tolist()\n",
    "    cat_features = X_train.columns.difference(num_features).tolist()\n",
    "    \n",
    "    pipeline = pipeline.get_binary_rfc_pipeline(num_features, cat_features)\n",
    "        \n",
    "    experiment_id = get_or_create_experiment(EXPERIMENT_NAME)\n",
    "    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME) # DEBUGGING\n",
    "    print(f\"Experiment: {experiment.name}, ID: {experiment.experiment_id}\") # DEBUGGING\n",
    "    \n",
    "    with mlflow.start_run(run_name=RUN_NAME):\n",
    "        # Create an Optuna study\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "\n",
    "        # Optimize the objective function\n",
    "        study.optimize(\n",
    "            partial(\n",
    "                tuning.objective_function,\n",
    "                X_train=X_train,\n",
    "                X_test=X_test,\n",
    "                y_train=y_train,\n",
    "                y_test=y_test,\n",
    "                pipeline=pipeline,\n",
    "                param_space=RFC_SPACE\n",
    "            ),\n",
    "            n_trials=10,\n",
    "            callbacks=[tuning.champion_callback]\n",
    "        )\n",
    "\n",
    "        best_params = study.best_params\n",
    "        print(\"BEST PARAMS FROM main(): \", best_params)\n",
    "\n",
    "        pipeline.set_params(**best_params)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_pred_proba = pipeline.predict_proba(X_test)\n",
    "\n",
    "        metrics = tuning.get_classification_metrics(y_test, y_pred, y_pred_proba, prefix='best_model_test')\n",
    "        log_confusion_matrix(y_test, y_pred)\n",
    "        log_roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        if SAVE_MODEL:\n",
    "            mlflow.sklearn.log_model(pipeline, \"best_model\")\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docker_ready",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
