{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **MLFLow-laboratory**\n",
    "> \n",
    "> \n",
    "> #### **a. Choose a model**\n",
    "> All scikit-learn models are available with one single import at `project_root/lib/models/sklearn.py`\n",
    "> ```py\n",
    "> # Import a model with:\n",
    "> from lib.models.sklearn import RandomForestClassifier\n",
    "> rfc = RandomForestClassifier()*\n",
    ">\n",
    "> # Or import all classes in a dict at once with:\n",
    "> from lib.models.sklearn import SKLEARN_CLASSIFIERS\n",
    "> # ... and instantiate them with:\n",
    "> rfc = SKLEARN_CLASSIFIERS['RandomForestClassisier'](bootstrap=True)\n",
    "> svc = SKLEARN_CLASSIFIERS['SVC']()\n",
    "> ```\n",
    "> #### **b. Select hyperparameters**\n",
    "> Automatic hyperparameter tuning is performed with Optuna library,\n",
    "> More information is available at [https://optuna.readthedocs.io/](https://optuna.readthedocs.io/en/stable/tutorial/index.html).  \n",
    "> \n",
    "> **WIP** An hyperparameter bank is being built, see at `project_root/lib/hp/...`\n",
    "> The goal is to store their name, a range if they are numerical or a list of choices.  \n",
    "> Here's an example:\n",
    "> ```py\n",
    "> # Hyperparameters for RandomForestClassifier\n",
    "> RFC_SPACE = {\n",
    ">     'classifier__n_estimators': (20, 200),\n",
    ">     'classifier__max_depth': (10, 100),\n",
    ">     'classifier__min_samples_split': (2, 20),\n",
    ">     'classifier__min_samples_leaf': (1, 2),\n",
    ">     'classifier__max_features': ['sqrt', 'log2', None],\n",
    ">     'classifier__criterion': ['gini', 'entropy'],\n",
    "> }\n",
    "> ```\n",
    "> Hyperparameter naming convention is `XXXC_SPACE` (ex `KNNC_SPACE`) for classification, / XXXR_SPACE (ex `RFR_SPACE`) for regression.  \n",
    "> \n",
    ">  Load hyperparameters:\n",
    "> ```bash\n",
    "> # Enable custom magics\n",
    "> %load_ext custom_magics\n",
    "> # load a set of hyperparameters\n",
    "> %load_variables ../lib/hp/sklearn.py RFC_SPACE\n",
    "> ```\n",
    "> #### **c. Retrieve scripts**\n",
    "> \n",
    "> Paste and execute one of these commands into a code cell to retrieve a mlflow script:\n",
    "> \n",
    "> **Classification**  \n",
    "> - Binary: `%load ../scripts/binary_classification.py`\n",
    "> \n",
    "> **Regression**  \n",
    "> - #TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Base config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Fill dataset info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'test_datasets/test_bin_class_loans.csv'\n",
    "TARGET_NAME = 'Loan_Status'\n",
    "FEATURES_TO_DROP = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE MODEL\n",
    "from lib.models.sklearn import SKLEARN_CLSSIFIERS\n",
    "clf = SKLEARN_CLSSIFIERS['RandomForestClassifier'](bootstrap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The custom_magics module is not an IPython extension.\n"
     ]
    }
   ],
   "source": [
    "%load_ext custom_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_variables lib/hp/sklearn.py RFC_SPACE\n",
    "RFC_SPACE = {   'classifier__criterion': ['gini', 'entropy'],\n",
    "    'classifier__max_depth': (10, 100),\n",
    "    'classifier__max_features': ['sqrt', 'log2', None],\n",
    "    'classifier__min_samples_leaf': (1, 2),\n",
    "    'classifier__min_samples_split': (2, 20),\n",
    "    'classifier__n_estimators': (20, 200)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load the script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-28 09:43:17,764] A new study created in memory with name: no-name-bedf1bf0-31a3-4ebc-a7dc-d2349606f719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mln/GIT/mlflow_laboratory/notebooks\n",
      "['custom_magics.py', 'backup', '__pycache__', 'TEMPLATE copy.ipynb', 'test_datasets', 'TEMPLATE.ipynb']\n",
      "MINIO_ENDPOINT_URL: set\n",
      "MINIO_ACCESS_KEY: set\n",
      "MINIO_SECRET_KEY: set\n",
      "MLFLOW_TRACKING_URI: http://localhost:5000\n",
      "mlflow tracking URI has been set to  http://localhost:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-28 09:43:17,887] Trial 0 finished with value: 0.8764044943820225 and parameters: {'classifier__criterion': 'entropy', 'classifier__max_depth': 83, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 4, 'classifier__n_estimators': 107}. Best is trial 0 with value: 0.8764044943820225.\n",
      "[I 2024-03-28 09:43:17,980] Trial 1 finished with value: 0.9060773480662984 and parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 40, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 14, 'classifier__n_estimators': 92}. Best is trial 1 with value: 0.9060773480662984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial trial 0 achieved value: 0.8764044943820225\n",
      "Trial 1 achieved value: 0.9060773480662984 with  3.2749% improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-28 09:43:18,132] Trial 2 finished with value: 0.8852459016393442 and parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 56, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 18, 'classifier__n_estimators': 184}. Best is trial 1 with value: 0.9060773480662984.\n",
      "[I 2024-03-28 09:43:18,396] Trial 3 finished with value: 0.7924528301886793 and parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 33, 'classifier__max_features': None, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 158}. Best is trial 1 with value: 0.9060773480662984.\n",
      "[I 2024-03-28 09:43:18,540] Trial 4 finished with value: 0.8901098901098901 and parameters: {'classifier__criterion': 'entropy', 'classifier__max_depth': 60, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 146}. Best is trial 1 with value: 0.9060773480662984.\n",
      "[I 2024-03-28 09:43:18,836] Trial 5 finished with value: 0.7701863354037267 and parameters: {'classifier__criterion': 'entropy', 'classifier__max_depth': 46, 'classifier__max_features': None, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 7, 'classifier__n_estimators': 167}. Best is trial 1 with value: 0.9060773480662984.\n",
      "[I 2024-03-28 09:43:18,910] Trial 6 finished with value: 0.8950276243093923 and parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 29, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 11, 'classifier__n_estimators': 43}. Best is trial 1 with value: 0.9060773480662984.\n",
      "[I 2024-03-28 09:43:19,077] Trial 7 finished with value: 0.9060773480662984 and parameters: {'classifier__criterion': 'entropy', 'classifier__max_depth': 30, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 19, 'classifier__n_estimators': 173}. Best is trial 1 with value: 0.9060773480662984.\n",
      "[I 2024-03-28 09:43:19,198] Trial 8 finished with value: 0.779874213836478 and parameters: {'classifier__criterion': 'entropy', 'classifier__max_depth': 95, 'classifier__max_features': None, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 15, 'classifier__n_estimators': 56}. Best is trial 1 with value: 0.9060773480662984.\n",
      "[I 2024-03-28 09:43:19,296] Trial 9 finished with value: 0.8950276243093923 and parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 12, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 105}. Best is trial 1 with value: 0.9060773480662984.\n",
      "[I 2024-03-28 09:43:19,386] Trial 10 finished with value: 0.9021739130434783 and parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 73, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 15, 'classifier__n_estimators': 76}. Best is trial 1 with value: 0.9060773480662984.\n",
      "[I 2024-03-28 09:43:19,516] Trial 11 finished with value: 0.88268156424581 and parameters: {'classifier__criterion': 'entropy', 'classifier__max_depth': 26, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 18, 'classifier__n_estimators': 129}. Best is trial 1 with value: 0.9060773480662984.\n",
      "[I 2024-03-28 09:43:19,673] Trial 12 finished with value: 0.8888888888888888 and parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 42, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20, 'classifier__n_estimators': 199}. Best is trial 1 with value: 0.9060773480662984.\n",
      "[I 2024-03-28 09:43:19,770] Trial 13 finished with value: 0.907103825136612 and parameters: {'classifier__criterion': 'entropy', 'classifier__max_depth': 11, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 14, 'classifier__n_estimators': 82}. Best is trial 13 with value: 0.907103825136612.\n",
      "[I 2024-03-28 09:43:19,866] Trial 14 finished with value: 0.8961748633879781 and parameters: {'classifier__criterion': 'entropy', 'classifier__max_depth': 10, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 14, 'classifier__n_estimators': 74}. Best is trial 13 with value: 0.907103825136612.\n",
      "[I 2024-03-28 09:43:19,927] Trial 15 finished with value: 0.9 and parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 19, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 9, 'classifier__n_estimators': 22}. Best is trial 13 with value: 0.907103825136612.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 achieved value: 0.907103825136612 with  0.1132% improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-28 09:43:20,028] Trial 16 finished with value: 0.88268156424581 and parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 44, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 13, 'classifier__n_estimators': 89}. Best is trial 13 with value: 0.907103825136612.\n",
      "[I 2024-03-28 09:43:20,163] Trial 17 finished with value: 0.9010989010989011 and parameters: {'classifier__criterion': 'entropy', 'classifier__max_depth': 20, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 16, 'classifier__n_estimators': 133}. Best is trial 13 with value: 0.907103825136612.\n",
      "[I 2024-03-28 09:43:20,282] Trial 18 finished with value: 0.8024691358024691 and parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 67, 'classifier__max_features': None, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 12, 'classifier__n_estimators': 52}. Best is trial 13 with value: 0.907103825136612.\n",
      "[I 2024-03-28 09:43:20,384] Trial 19 finished with value: 0.8839779005524862 and parameters: {'classifier__criterion': 'entropy', 'classifier__max_depth': 37, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 8, 'classifier__n_estimators': 83}. Best is trial 13 with value: 0.907103825136612.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS FROM main():  {'classifier__criterion': 'entropy', 'classifier__max_depth': 11, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 14, 'classifier__n_estimators': 82}\n"
     ]
    }
   ],
   "source": [
    "# %load ../scripts/binary_classification.py\n",
    "# file: binary_classification.py\n",
    "\n",
    "# FIND REGULAR IMPORTS IN laboratory/config.py\n",
    "from laboratory.config import *\n",
    "from laboratory.mlflow import get_or_create_experiment, set_mlflow_tracking_uri_from_env\n",
    "\n",
    "handle_warnings()\n",
    "env_vars = get_environment()\n",
    "set_mlflow_tracking_uri_from_env(env_vars)\n",
    "\n",
    "# Custom modules\n",
    "import laboratory.dataset as dataset\n",
    "import laboratory.sklearn as sklearn\n",
    "import laboratory.tuning as tuning\n",
    "from laboratory.mlflow import get_run_name\n",
    "from laboratory.artifacts import log_confusion_matrix, log_roc_curve\n",
    "from lib.models.sklearn import RandomForestClassifier # Placeholder\n",
    "\n",
    "###############################################\n",
    "#################### SETUP ####################\n",
    "######## Fill experiment input here ########### \n",
    "\n",
    "DATASET_PATH = DATASET_PATH # Placeholder \n",
    "DF = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "TARGET_NAME = TARGET_NAME # Placeholder\n",
    "FEATURES_TO_DROP = FEATURES_TO_DROP # Placeholder\n",
    "\n",
    "DATASET_SPLIT_PARAMS = {'test_size': 0.2, 'stratify': DF[TARGET_NAME], 'random_state': 42}\n",
    "\n",
    "CLASSIFIER = clf # Placeholder\n",
    "SPACE = RFC_SPACE # Placeholder\n",
    "SAVE_MODEL = False\n",
    "\n",
    "OPTUNA_STUDY_TRIALS = 20\n",
    "OPTUNA_METRIC_TO_MAXIMIZE = 'f1_score'  \n",
    "\n",
    "\n",
    "EXPERIMENT_NAME = DATASET_PATH.split('/')[-1] # Is file name by default\n",
    "RUN_NAME = get_run_name(run_name=None)\n",
    "\n",
    "\n",
    "###############################################\n",
    "#################### MAIN #####################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = DF.copy()\n",
    "    \n",
    "    if FEATURES_TO_DROP is not None:\n",
    "        df = df.drop(columns=FEATURES_TO_DROP)    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df.drop(columns=TARGET_NAME), df[TARGET_NAME], **DATASET_SPLIT_PARAMS\n",
    "    )\n",
    "    \n",
    "    num_features = X_train.select_dtypes([np.number]).columns.tolist()\n",
    "    cat_features = X_train.columns.difference(num_features).tolist()\n",
    "\n",
    "    PREPROCESSING_PIPELINE = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numerical', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "            ]), num_features),\n",
    "            ('categorical', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                ('onehot', OneHotEncoder())\n",
    "            ]), cat_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    CLASSIFICATION_PIPELINE = Pipeline(steps=[\n",
    "        ('preprocessing', PREPROCESSING_PIPELINE),\n",
    "        ('classifier', CLASSIFIER)\n",
    "    ])\n",
    "\n",
    "    experiment_id = get_or_create_experiment(EXPERIMENT_NAME)\n",
    "    \n",
    "    with mlflow.start_run(run_name=RUN_NAME):\n",
    "        # Create an Optuna study\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "\n",
    "        # Optimize the objective function\n",
    "        study.optimize(\n",
    "            partial(\n",
    "                tuning.objective_function,\n",
    "                X_train=X_train,\n",
    "                X_test=X_test,\n",
    "                y_train=y_train,\n",
    "                y_test=y_test,\n",
    "                pipeline=CLASSIFICATION_PIPELINE,\n",
    "                param_space=SPACE,\n",
    "                metric_to_maximize=OPTUNA_METRIC_TO_MAXIMIZE\n",
    "            ),\n",
    "            n_trials=OPTUNA_STUDY_TRIALS,\n",
    "            callbacks=[tuning.champion_callback]\n",
    "        )\n",
    "\n",
    "        best_params = study.best_params\n",
    "        print(\"BEST PARAMS FROM main(): \", best_params)\n",
    "\n",
    "        CLASSIFICATION_PIPELINE.set_params(**best_params)\n",
    "        CLASSIFICATION_PIPELINE.fit(X_train, y_train)\n",
    "        y_pred = CLASSIFICATION_PIPELINE.predict(X_test)\n",
    "        y_pred_proba = CLASSIFICATION_PIPELINE.predict_proba(X_test)\n",
    "\n",
    "        metrics = tuning.get_classification_metrics(y_test, y_pred, y_pred_proba)\n",
    "        log_confusion_matrix(y_test, y_pred)\n",
    "        log_roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        if SAVE_MODEL:\n",
    "            mlflow.sklearn.log_model(sklearn, \"best_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docker_ready",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
